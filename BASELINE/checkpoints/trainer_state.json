{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 7378,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0002710761724044456,
      "grad_norm": 4.713412761688232,
      "learning_rate": 4e-05,
      "loss": 5.8874,
      "step": 1
    },
    {
      "epoch": 0.013553808620222282,
      "grad_norm": 22.290794372558594,
      "learning_rate": 3.973434535104365e-05,
      "loss": 4.0504,
      "step": 50
    },
    {
      "epoch": 0.027107617240444564,
      "grad_norm": 16.170272827148438,
      "learning_rate": 3.94632691786392e-05,
      "loss": 2.575,
      "step": 100
    },
    {
      "epoch": 0.040661425860666844,
      "grad_norm": 14.246940612792969,
      "learning_rate": 3.9192193006234753e-05,
      "loss": 2.2492,
      "step": 150
    },
    {
      "epoch": 0.05421523448088913,
      "grad_norm": 11.03701114654541,
      "learning_rate": 3.8921116833830305e-05,
      "loss": 1.9613,
      "step": 200
    },
    {
      "epoch": 0.06776904310111141,
      "grad_norm": 12.732230186462402,
      "learning_rate": 3.8650040661425864e-05,
      "loss": 1.7494,
      "step": 250
    },
    {
      "epoch": 0.08132285172133369,
      "grad_norm": 11.746731758117676,
      "learning_rate": 3.8378964489021415e-05,
      "loss": 1.6219,
      "step": 300
    },
    {
      "epoch": 0.09487666034155598,
      "grad_norm": 12.644518852233887,
      "learning_rate": 3.8107888316616974e-05,
      "loss": 1.6288,
      "step": 350
    },
    {
      "epoch": 0.10843046896177826,
      "grad_norm": 12.272512435913086,
      "learning_rate": 3.7836812144212526e-05,
      "loss": 1.5078,
      "step": 400
    },
    {
      "epoch": 0.12198427758200055,
      "grad_norm": 16.695743560791016,
      "learning_rate": 3.7565735971808084e-05,
      "loss": 1.4648,
      "step": 450
    },
    {
      "epoch": 0.13553808620222282,
      "grad_norm": 32.916385650634766,
      "learning_rate": 3.7294659799403636e-05,
      "loss": 1.4912,
      "step": 500
    },
    {
      "epoch": 0.14909189482244511,
      "grad_norm": 16.76543426513672,
      "learning_rate": 3.7023583626999194e-05,
      "loss": 1.4391,
      "step": 550
    },
    {
      "epoch": 0.16264570344266738,
      "grad_norm": 12.034507751464844,
      "learning_rate": 3.6752507454594746e-05,
      "loss": 1.3766,
      "step": 600
    },
    {
      "epoch": 0.17619951206288967,
      "grad_norm": 12.793313026428223,
      "learning_rate": 3.64814312821903e-05,
      "loss": 1.3418,
      "step": 650
    },
    {
      "epoch": 0.18975332068311196,
      "grad_norm": 10.84486198425293,
      "learning_rate": 3.621035510978585e-05,
      "loss": 1.2682,
      "step": 700
    },
    {
      "epoch": 0.20330712930333425,
      "grad_norm": 11.293388366699219,
      "learning_rate": 3.593927893738141e-05,
      "loss": 1.3974,
      "step": 750
    },
    {
      "epoch": 0.2168609379235565,
      "grad_norm": 11.855429649353027,
      "learning_rate": 3.566820276497696e-05,
      "loss": 1.3287,
      "step": 800
    },
    {
      "epoch": 0.2304147465437788,
      "grad_norm": 13.339237213134766,
      "learning_rate": 3.539712659257252e-05,
      "loss": 1.3583,
      "step": 850
    },
    {
      "epoch": 0.2439685551640011,
      "grad_norm": 11.361090660095215,
      "learning_rate": 3.512605042016807e-05,
      "loss": 1.3066,
      "step": 900
    },
    {
      "epoch": 0.2575223637842234,
      "grad_norm": 14.05754280090332,
      "learning_rate": 3.485497424776362e-05,
      "loss": 1.2957,
      "step": 950
    },
    {
      "epoch": 0.27107617240444565,
      "grad_norm": 12.096677780151367,
      "learning_rate": 3.458389807535918e-05,
      "loss": 1.2295,
      "step": 1000
    },
    {
      "epoch": 0.2846299810246679,
      "grad_norm": 12.559021949768066,
      "learning_rate": 3.431282190295473e-05,
      "loss": 1.3144,
      "step": 1050
    },
    {
      "epoch": 0.29818378964489023,
      "grad_norm": 8.564041137695312,
      "learning_rate": 3.404174573055029e-05,
      "loss": 1.223,
      "step": 1100
    },
    {
      "epoch": 0.3117375982651125,
      "grad_norm": 12.950393676757812,
      "learning_rate": 3.377066955814584e-05,
      "loss": 1.3586,
      "step": 1150
    },
    {
      "epoch": 0.32529140688533476,
      "grad_norm": 11.253891944885254,
      "learning_rate": 3.34995933857414e-05,
      "loss": 1.2416,
      "step": 1200
    },
    {
      "epoch": 0.3388452155055571,
      "grad_norm": 12.703157424926758,
      "learning_rate": 3.3228517213336946e-05,
      "loss": 1.2899,
      "step": 1250
    },
    {
      "epoch": 0.35239902412577934,
      "grad_norm": 12.321765899658203,
      "learning_rate": 3.2957441040932504e-05,
      "loss": 1.2167,
      "step": 1300
    },
    {
      "epoch": 0.3659528327460016,
      "grad_norm": 10.153644561767578,
      "learning_rate": 3.2686364868528056e-05,
      "loss": 1.2499,
      "step": 1350
    },
    {
      "epoch": 0.3795066413662239,
      "grad_norm": 10.911757469177246,
      "learning_rate": 3.2415288696123614e-05,
      "loss": 1.2376,
      "step": 1400
    },
    {
      "epoch": 0.3930604499864462,
      "grad_norm": 16.229589462280273,
      "learning_rate": 3.2144212523719166e-05,
      "loss": 1.2204,
      "step": 1450
    },
    {
      "epoch": 0.4066142586066685,
      "grad_norm": 10.2903470993042,
      "learning_rate": 3.1873136351314724e-05,
      "loss": 1.2491,
      "step": 1500
    },
    {
      "epoch": 0.42016806722689076,
      "grad_norm": 11.852941513061523,
      "learning_rate": 3.1602060178910276e-05,
      "loss": 1.1866,
      "step": 1550
    },
    {
      "epoch": 0.433721875847113,
      "grad_norm": 12.890586853027344,
      "learning_rate": 3.133098400650583e-05,
      "loss": 1.1943,
      "step": 1600
    },
    {
      "epoch": 0.44727568446733534,
      "grad_norm": 12.274670600891113,
      "learning_rate": 3.1059907834101386e-05,
      "loss": 1.2313,
      "step": 1650
    },
    {
      "epoch": 0.4608294930875576,
      "grad_norm": 8.411508560180664,
      "learning_rate": 3.078883166169694e-05,
      "loss": 1.1873,
      "step": 1700
    },
    {
      "epoch": 0.47438330170777987,
      "grad_norm": 9.026895523071289,
      "learning_rate": 3.05177554892925e-05,
      "loss": 1.0621,
      "step": 1750
    },
    {
      "epoch": 0.4879371103280022,
      "grad_norm": 15.127429008483887,
      "learning_rate": 3.0246679316888052e-05,
      "loss": 1.0859,
      "step": 1800
    },
    {
      "epoch": 0.5014909189482244,
      "grad_norm": 11.014141082763672,
      "learning_rate": 2.99756031444836e-05,
      "loss": 1.1321,
      "step": 1850
    },
    {
      "epoch": 0.5150447275684468,
      "grad_norm": 9.737386703491211,
      "learning_rate": 2.9704526972079155e-05,
      "loss": 1.0861,
      "step": 1900
    },
    {
      "epoch": 0.528598536188669,
      "grad_norm": 13.027850151062012,
      "learning_rate": 2.943345079967471e-05,
      "loss": 1.1535,
      "step": 1950
    },
    {
      "epoch": 0.5421523448088913,
      "grad_norm": 8.92154312133789,
      "learning_rate": 2.9162374627270265e-05,
      "loss": 1.1357,
      "step": 2000
    },
    {
      "epoch": 0.5557061534291136,
      "grad_norm": 17.43637466430664,
      "learning_rate": 2.889129845486582e-05,
      "loss": 1.1124,
      "step": 2050
    },
    {
      "epoch": 0.5692599620493358,
      "grad_norm": 10.640390396118164,
      "learning_rate": 2.8620222282461376e-05,
      "loss": 1.1917,
      "step": 2100
    },
    {
      "epoch": 0.5828137706695582,
      "grad_norm": 17.556060791015625,
      "learning_rate": 2.8349146110056927e-05,
      "loss": 1.0744,
      "step": 2150
    },
    {
      "epoch": 0.5963675792897805,
      "grad_norm": 17.77240562438965,
      "learning_rate": 2.8078069937652482e-05,
      "loss": 1.0659,
      "step": 2200
    },
    {
      "epoch": 0.6099213879100027,
      "grad_norm": 12.899730682373047,
      "learning_rate": 2.7806993765248038e-05,
      "loss": 1.109,
      "step": 2250
    },
    {
      "epoch": 0.623475196530225,
      "grad_norm": 10.201904296875,
      "learning_rate": 2.7535917592843593e-05,
      "loss": 1.1658,
      "step": 2300
    },
    {
      "epoch": 0.6370290051504472,
      "grad_norm": 6.949125289916992,
      "learning_rate": 2.7264841420439148e-05,
      "loss": 1.1718,
      "step": 2350
    },
    {
      "epoch": 0.6505828137706695,
      "grad_norm": 15.776742935180664,
      "learning_rate": 2.69937652480347e-05,
      "loss": 1.1618,
      "step": 2400
    },
    {
      "epoch": 0.6641366223908919,
      "grad_norm": 11.945663452148438,
      "learning_rate": 2.672268907563025e-05,
      "loss": 1.085,
      "step": 2450
    },
    {
      "epoch": 0.6776904310111141,
      "grad_norm": 12.463974952697754,
      "learning_rate": 2.6451612903225806e-05,
      "loss": 1.146,
      "step": 2500
    },
    {
      "epoch": 0.6912442396313364,
      "grad_norm": 13.25588607788086,
      "learning_rate": 2.618053673082136e-05,
      "loss": 1.0978,
      "step": 2550
    },
    {
      "epoch": 0.7047980482515587,
      "grad_norm": 11.96466064453125,
      "learning_rate": 2.5909460558416917e-05,
      "loss": 1.078,
      "step": 2600
    },
    {
      "epoch": 0.7183518568717809,
      "grad_norm": 9.866539001464844,
      "learning_rate": 2.563838438601247e-05,
      "loss": 1.1234,
      "step": 2650
    },
    {
      "epoch": 0.7319056654920032,
      "grad_norm": 12.604205131530762,
      "learning_rate": 2.5367308213608027e-05,
      "loss": 1.0636,
      "step": 2700
    },
    {
      "epoch": 0.7454594741122256,
      "grad_norm": 11.389139175415039,
      "learning_rate": 2.5096232041203582e-05,
      "loss": 1.0564,
      "step": 2750
    },
    {
      "epoch": 0.7590132827324478,
      "grad_norm": 12.09650993347168,
      "learning_rate": 2.4825155868799137e-05,
      "loss": 1.0753,
      "step": 2800
    },
    {
      "epoch": 0.7725670913526701,
      "grad_norm": 8.136466979980469,
      "learning_rate": 2.455407969639469e-05,
      "loss": 1.0751,
      "step": 2850
    },
    {
      "epoch": 0.7861208999728924,
      "grad_norm": 12.523283958435059,
      "learning_rate": 2.4283003523990244e-05,
      "loss": 1.0534,
      "step": 2900
    },
    {
      "epoch": 0.7996747085931146,
      "grad_norm": 14.446721076965332,
      "learning_rate": 2.4011927351585796e-05,
      "loss": 0.979,
      "step": 2950
    },
    {
      "epoch": 0.813228517213337,
      "grad_norm": 11.256251335144043,
      "learning_rate": 2.374085117918135e-05,
      "loss": 1.0471,
      "step": 3000
    },
    {
      "epoch": 0.8267823258335593,
      "grad_norm": 14.127694129943848,
      "learning_rate": 2.3469775006776906e-05,
      "loss": 1.0511,
      "step": 3050
    },
    {
      "epoch": 0.8403361344537815,
      "grad_norm": 11.830827713012695,
      "learning_rate": 2.319869883437246e-05,
      "loss": 1.0485,
      "step": 3100
    },
    {
      "epoch": 0.8538899430740038,
      "grad_norm": 11.293352127075195,
      "learning_rate": 2.2927622661968013e-05,
      "loss": 1.0582,
      "step": 3150
    },
    {
      "epoch": 0.867443751694226,
      "grad_norm": 11.512338638305664,
      "learning_rate": 2.2656546489563568e-05,
      "loss": 0.9662,
      "step": 3200
    },
    {
      "epoch": 0.8809975603144483,
      "grad_norm": 10.478434562683105,
      "learning_rate": 2.2385470317159123e-05,
      "loss": 1.11,
      "step": 3250
    },
    {
      "epoch": 0.8945513689346707,
      "grad_norm": 13.404009819030762,
      "learning_rate": 2.2114394144754678e-05,
      "loss": 1.1176,
      "step": 3300
    },
    {
      "epoch": 0.908105177554893,
      "grad_norm": 10.440993309020996,
      "learning_rate": 2.1843317972350233e-05,
      "loss": 1.0877,
      "step": 3350
    },
    {
      "epoch": 0.9216589861751152,
      "grad_norm": 11.784242630004883,
      "learning_rate": 2.1572241799945788e-05,
      "loss": 1.0558,
      "step": 3400
    },
    {
      "epoch": 0.9352127947953375,
      "grad_norm": 13.763387680053711,
      "learning_rate": 2.1301165627541343e-05,
      "loss": 1.0112,
      "step": 3450
    },
    {
      "epoch": 0.9487666034155597,
      "grad_norm": 8.86008071899414,
      "learning_rate": 2.10300894551369e-05,
      "loss": 1.0488,
      "step": 3500
    },
    {
      "epoch": 0.962320412035782,
      "grad_norm": 11.827881813049316,
      "learning_rate": 2.0759013282732447e-05,
      "loss": 1.0312,
      "step": 3550
    },
    {
      "epoch": 0.9758742206560044,
      "grad_norm": 12.946592330932617,
      "learning_rate": 2.0487937110328002e-05,
      "loss": 1.0178,
      "step": 3600
    },
    {
      "epoch": 0.9894280292762266,
      "grad_norm": 16.934263229370117,
      "learning_rate": 2.0216860937923557e-05,
      "loss": 0.9666,
      "step": 3650
    },
    {
      "epoch": 1.0029818378964488,
      "grad_norm": 11.7286958694458,
      "learning_rate": 1.9945784765519112e-05,
      "loss": 0.9306,
      "step": 3700
    },
    {
      "epoch": 1.0165356465166713,
      "grad_norm": 6.543426513671875,
      "learning_rate": 1.9674708593114667e-05,
      "loss": 0.7322,
      "step": 3750
    },
    {
      "epoch": 1.0300894551368935,
      "grad_norm": 4.909475803375244,
      "learning_rate": 1.9403632420710222e-05,
      "loss": 0.7699,
      "step": 3800
    },
    {
      "epoch": 1.0436432637571158,
      "grad_norm": 9.639297485351562,
      "learning_rate": 1.9132556248305777e-05,
      "loss": 0.7162,
      "step": 3850
    },
    {
      "epoch": 1.057197072377338,
      "grad_norm": 10.61050033569336,
      "learning_rate": 1.886148007590133e-05,
      "loss": 0.7285,
      "step": 3900
    },
    {
      "epoch": 1.0707508809975603,
      "grad_norm": 12.244142532348633,
      "learning_rate": 1.8590403903496884e-05,
      "loss": 0.6503,
      "step": 3950
    },
    {
      "epoch": 1.0843046896177826,
      "grad_norm": 12.922134399414062,
      "learning_rate": 1.831932773109244e-05,
      "loss": 0.7509,
      "step": 4000
    },
    {
      "epoch": 1.0978584982380049,
      "grad_norm": 9.22331428527832,
      "learning_rate": 1.804825155868799e-05,
      "loss": 0.7909,
      "step": 4050
    },
    {
      "epoch": 1.1114123068582271,
      "grad_norm": 11.065775871276855,
      "learning_rate": 1.7777175386283546e-05,
      "loss": 0.7643,
      "step": 4100
    },
    {
      "epoch": 1.1249661154784494,
      "grad_norm": 7.121882915496826,
      "learning_rate": 1.75060992138791e-05,
      "loss": 0.7057,
      "step": 4150
    },
    {
      "epoch": 1.1385199240986716,
      "grad_norm": 10.761573791503906,
      "learning_rate": 1.7235023041474656e-05,
      "loss": 0.6653,
      "step": 4200
    },
    {
      "epoch": 1.1520737327188941,
      "grad_norm": 13.133247375488281,
      "learning_rate": 1.6963946869070208e-05,
      "loss": 0.7295,
      "step": 4250
    },
    {
      "epoch": 1.1656275413391164,
      "grad_norm": 10.460036277770996,
      "learning_rate": 1.6692870696665763e-05,
      "loss": 0.6862,
      "step": 4300
    },
    {
      "epoch": 1.1791813499593387,
      "grad_norm": 12.58971118927002,
      "learning_rate": 1.6421794524261318e-05,
      "loss": 0.7634,
      "step": 4350
    },
    {
      "epoch": 1.192735158579561,
      "grad_norm": 9.417717933654785,
      "learning_rate": 1.6150718351856873e-05,
      "loss": 0.7507,
      "step": 4400
    },
    {
      "epoch": 1.2062889671997832,
      "grad_norm": 9.074382781982422,
      "learning_rate": 1.587964217945243e-05,
      "loss": 0.6941,
      "step": 4450
    },
    {
      "epoch": 1.2198427758200054,
      "grad_norm": 10.398962020874023,
      "learning_rate": 1.5608566007047984e-05,
      "loss": 0.7203,
      "step": 4500
    },
    {
      "epoch": 1.2333965844402277,
      "grad_norm": 8.313621520996094,
      "learning_rate": 1.5337489834643535e-05,
      "loss": 0.7174,
      "step": 4550
    },
    {
      "epoch": 1.24695039306045,
      "grad_norm": 14.075519561767578,
      "learning_rate": 1.506641366223909e-05,
      "loss": 0.6935,
      "step": 4600
    },
    {
      "epoch": 1.2605042016806722,
      "grad_norm": 12.982285499572754,
      "learning_rate": 1.4795337489834645e-05,
      "loss": 0.7219,
      "step": 4650
    },
    {
      "epoch": 1.2740580103008945,
      "grad_norm": 7.822503089904785,
      "learning_rate": 1.4524261317430199e-05,
      "loss": 0.7495,
      "step": 4700
    },
    {
      "epoch": 1.2876118189211168,
      "grad_norm": 5.756546974182129,
      "learning_rate": 1.4253185145025754e-05,
      "loss": 0.713,
      "step": 4750
    },
    {
      "epoch": 1.301165627541339,
      "grad_norm": 10.149231910705566,
      "learning_rate": 1.3982108972621309e-05,
      "loss": 0.7516,
      "step": 4800
    },
    {
      "epoch": 1.3147194361615613,
      "grad_norm": 9.500702857971191,
      "learning_rate": 1.371103280021686e-05,
      "loss": 0.748,
      "step": 4850
    },
    {
      "epoch": 1.3282732447817835,
      "grad_norm": 11.944259643554688,
      "learning_rate": 1.3439956627812416e-05,
      "loss": 0.7887,
      "step": 4900
    },
    {
      "epoch": 1.341827053402006,
      "grad_norm": 7.529603481292725,
      "learning_rate": 1.3168880455407971e-05,
      "loss": 0.6896,
      "step": 4950
    },
    {
      "epoch": 1.3553808620222283,
      "grad_norm": 11.623964309692383,
      "learning_rate": 1.2897804283003526e-05,
      "loss": 0.6936,
      "step": 5000
    },
    {
      "epoch": 1.3689346706424506,
      "grad_norm": 8.129219055175781,
      "learning_rate": 1.262672811059908e-05,
      "loss": 0.7555,
      "step": 5050
    },
    {
      "epoch": 1.3824884792626728,
      "grad_norm": 10.30565357208252,
      "learning_rate": 1.2355651938194633e-05,
      "loss": 0.7799,
      "step": 5100
    },
    {
      "epoch": 1.396042287882895,
      "grad_norm": 7.734461307525635,
      "learning_rate": 1.2084575765790188e-05,
      "loss": 0.7198,
      "step": 5150
    },
    {
      "epoch": 1.4095960965031173,
      "grad_norm": 10.234513282775879,
      "learning_rate": 1.1813499593385742e-05,
      "loss": 0.7311,
      "step": 5200
    },
    {
      "epoch": 1.4231499051233396,
      "grad_norm": 11.998798370361328,
      "learning_rate": 1.1542423420981297e-05,
      "loss": 0.7111,
      "step": 5250
    },
    {
      "epoch": 1.4367037137435619,
      "grad_norm": 7.0507354736328125,
      "learning_rate": 1.1271347248576852e-05,
      "loss": 0.6661,
      "step": 5300
    },
    {
      "epoch": 1.4502575223637844,
      "grad_norm": 14.120672225952148,
      "learning_rate": 1.1000271076172407e-05,
      "loss": 0.7515,
      "step": 5350
    },
    {
      "epoch": 1.4638113309840066,
      "grad_norm": 6.35235071182251,
      "learning_rate": 1.0729194903767959e-05,
      "loss": 0.6885,
      "step": 5400
    },
    {
      "epoch": 1.4773651396042289,
      "grad_norm": 8.688454627990723,
      "learning_rate": 1.0458118731363514e-05,
      "loss": 0.7463,
      "step": 5450
    },
    {
      "epoch": 1.4909189482244511,
      "grad_norm": 12.577413558959961,
      "learning_rate": 1.0187042558959069e-05,
      "loss": 0.7159,
      "step": 5500
    },
    {
      "epoch": 1.5044727568446734,
      "grad_norm": 8.142644882202148,
      "learning_rate": 9.915966386554622e-06,
      "loss": 0.7382,
      "step": 5550
    },
    {
      "epoch": 1.5180265654648957,
      "grad_norm": 8.069315910339355,
      "learning_rate": 9.644890214150177e-06,
      "loss": 0.7517,
      "step": 5600
    },
    {
      "epoch": 1.531580374085118,
      "grad_norm": 8.666797637939453,
      "learning_rate": 9.37381404174573e-06,
      "loss": 0.7135,
      "step": 5650
    },
    {
      "epoch": 1.5451341827053402,
      "grad_norm": 9.719548225402832,
      "learning_rate": 9.102737869341286e-06,
      "loss": 0.7056,
      "step": 5700
    },
    {
      "epoch": 1.5586879913255625,
      "grad_norm": 5.296294212341309,
      "learning_rate": 8.83166169693684e-06,
      "loss": 0.6798,
      "step": 5750
    },
    {
      "epoch": 1.5722417999457847,
      "grad_norm": 7.590516567230225,
      "learning_rate": 8.560585524532394e-06,
      "loss": 0.6581,
      "step": 5800
    },
    {
      "epoch": 1.585795608566007,
      "grad_norm": 7.655038356781006,
      "learning_rate": 8.28950935212795e-06,
      "loss": 0.7259,
      "step": 5850
    },
    {
      "epoch": 1.5993494171862292,
      "grad_norm": 7.831981182098389,
      "learning_rate": 8.018433179723503e-06,
      "loss": 0.7671,
      "step": 5900
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 9.320491790771484,
      "learning_rate": 7.747357007319058e-06,
      "loss": 0.7201,
      "step": 5950
    },
    {
      "epoch": 1.6264570344266738,
      "grad_norm": 15.94056224822998,
      "learning_rate": 7.476280834914612e-06,
      "loss": 0.6852,
      "step": 6000
    },
    {
      "epoch": 1.640010843046896,
      "grad_norm": 7.892110347747803,
      "learning_rate": 7.205204662510166e-06,
      "loss": 0.7293,
      "step": 6050
    },
    {
      "epoch": 1.6535646516671183,
      "grad_norm": 9.634613990783691,
      "learning_rate": 6.934128490105721e-06,
      "loss": 0.7137,
      "step": 6100
    },
    {
      "epoch": 1.6671184602873408,
      "grad_norm": 6.938510894775391,
      "learning_rate": 6.663052317701275e-06,
      "loss": 0.7348,
      "step": 6150
    },
    {
      "epoch": 1.680672268907563,
      "grad_norm": 13.899338722229004,
      "learning_rate": 6.3919761452968284e-06,
      "loss": 0.762,
      "step": 6200
    },
    {
      "epoch": 1.6942260775277853,
      "grad_norm": 14.182639122009277,
      "learning_rate": 6.1208999728923835e-06,
      "loss": 0.6852,
      "step": 6250
    },
    {
      "epoch": 1.7077798861480076,
      "grad_norm": 14.25557804107666,
      "learning_rate": 5.849823800487937e-06,
      "loss": 0.7128,
      "step": 6300
    },
    {
      "epoch": 1.7213336947682298,
      "grad_norm": 10.126891136169434,
      "learning_rate": 5.578747628083492e-06,
      "loss": 0.7142,
      "step": 6350
    },
    {
      "epoch": 1.734887503388452,
      "grad_norm": 11.909871101379395,
      "learning_rate": 5.307671455679046e-06,
      "loss": 0.7872,
      "step": 6400
    },
    {
      "epoch": 1.7484413120086746,
      "grad_norm": 14.817442893981934,
      "learning_rate": 5.0365952832746e-06,
      "loss": 0.7397,
      "step": 6450
    },
    {
      "epoch": 1.7619951206288968,
      "grad_norm": 13.004867553710938,
      "learning_rate": 4.765519110870155e-06,
      "loss": 0.7088,
      "step": 6500
    },
    {
      "epoch": 1.7755489292491191,
      "grad_norm": 10.56462287902832,
      "learning_rate": 4.494442938465709e-06,
      "loss": 0.657,
      "step": 6550
    },
    {
      "epoch": 1.7891027378693414,
      "grad_norm": 6.659750938415527,
      "learning_rate": 4.223366766061263e-06,
      "loss": 0.7044,
      "step": 6600
    },
    {
      "epoch": 1.8026565464895636,
      "grad_norm": 4.613976955413818,
      "learning_rate": 3.952290593656818e-06,
      "loss": 0.693,
      "step": 6650
    },
    {
      "epoch": 1.816210355109786,
      "grad_norm": 7.4391398429870605,
      "learning_rate": 3.681214421252372e-06,
      "loss": 0.6665,
      "step": 6700
    },
    {
      "epoch": 1.8297641637300082,
      "grad_norm": 11.277647972106934,
      "learning_rate": 3.4101382488479266e-06,
      "loss": 0.7325,
      "step": 6750
    },
    {
      "epoch": 1.8433179723502304,
      "grad_norm": 12.31381893157959,
      "learning_rate": 3.139062076443481e-06,
      "loss": 0.6885,
      "step": 6800
    },
    {
      "epoch": 1.8568717809704527,
      "grad_norm": 10.561732292175293,
      "learning_rate": 2.867985904039035e-06,
      "loss": 0.7276,
      "step": 6850
    },
    {
      "epoch": 1.870425589590675,
      "grad_norm": 9.755167961120605,
      "learning_rate": 2.5969097316345894e-06,
      "loss": 0.6987,
      "step": 6900
    },
    {
      "epoch": 1.8839793982108972,
      "grad_norm": 14.110204696655273,
      "learning_rate": 2.325833559230144e-06,
      "loss": 0.6757,
      "step": 6950
    },
    {
      "epoch": 1.8975332068311195,
      "grad_norm": 10.568143844604492,
      "learning_rate": 2.0547573868256983e-06,
      "loss": 0.6884,
      "step": 7000
    },
    {
      "epoch": 1.9110870154513417,
      "grad_norm": 9.874466896057129,
      "learning_rate": 1.7836812144212526e-06,
      "loss": 0.7026,
      "step": 7050
    },
    {
      "epoch": 1.924640824071564,
      "grad_norm": 15.884082794189453,
      "learning_rate": 1.5126050420168068e-06,
      "loss": 0.7165,
      "step": 7100
    },
    {
      "epoch": 1.9381946326917863,
      "grad_norm": 11.626766204833984,
      "learning_rate": 1.241528869612361e-06,
      "loss": 0.6648,
      "step": 7150
    },
    {
      "epoch": 1.9517484413120085,
      "grad_norm": 10.830194473266602,
      "learning_rate": 9.704526972079156e-07,
      "loss": 0.641,
      "step": 7200
    },
    {
      "epoch": 1.9653022499322308,
      "grad_norm": 14.719908714294434,
      "learning_rate": 6.993765248034698e-07,
      "loss": 0.6951,
      "step": 7250
    },
    {
      "epoch": 1.9788560585524533,
      "grad_norm": 8.716062545776367,
      "learning_rate": 4.2830035239902414e-07,
      "loss": 0.71,
      "step": 7300
    },
    {
      "epoch": 1.9924098671726755,
      "grad_norm": 20.09208106994629,
      "learning_rate": 1.572241799945785e-07,
      "loss": 0.7065,
      "step": 7350
    },
    {
      "epoch": 2.0,
      "step": 7378,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9955174634695118,
      "train_runtime": 643.3434,
      "train_samples_per_second": 275.2,
      "train_steps_per_second": 11.468
    }
  ],
  "logging_steps": 50,
  "max_steps": 7378,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.4696551139946496e+16,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
